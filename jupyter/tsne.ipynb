{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd6cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eade12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsk = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(f\"data/hsk{i}.csv\", names=[\"simplified\", \"pinyin\", \"meanings\"])\n",
    "        .assign(level=i)\n",
    "    )\n",
    "    for i in range(1,7)\n",
    ")[[\"simplified\", \"pinyin\", \"meanings\", \"level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf184a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simplified</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>meanings</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>爱</td>\n",
       "      <td>ai4</td>\n",
       "      <td>to love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>八</td>\n",
       "      <td>ba1</td>\n",
       "      <td>eight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>爸爸</td>\n",
       "      <td>ba4 ba5</td>\n",
       "      <td>(informal) father</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>杯子</td>\n",
       "      <td>bei1 zi5</td>\n",
       "      <td>cup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北京</td>\n",
       "      <td>Bei3 jing1</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>座右铭</td>\n",
       "      <td>zuo4 you4 ming2</td>\n",
       "      <td>motto</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>作弊</td>\n",
       "      <td>zuo4 bi4</td>\n",
       "      <td>to practice fraud</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>作废</td>\n",
       "      <td>zuo4 fei4</td>\n",
       "      <td>to become invalid</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>作风</td>\n",
       "      <td>zuo4 feng1</td>\n",
       "      <td>style</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>作息</td>\n",
       "      <td>zuo4 xi1</td>\n",
       "      <td>work and rest</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     simplified           pinyin           meanings  level\n",
       "0             爱              ai4            to love      1\n",
       "1             八              ba1              eight      1\n",
       "2            爸爸          ba4 ba5  (informal) father      1\n",
       "3            杯子         bei1 zi5                cup      1\n",
       "4            北京       Bei3 jing1            Beijing      1\n",
       "...         ...              ...                ...    ...\n",
       "2495        座右铭  zuo4 you4 ming2              motto      6\n",
       "2496         作弊         zuo4 bi4  to practice fraud      6\n",
       "2497         作废        zuo4 fei4  to become invalid      6\n",
       "2498         作风       zuo4 feng1              style      6\n",
       "2499         作息         zuo4 xi1      work and rest      6\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vowelsToTone(pinyin):\n",
    "    accentMap = {\n",
    "        \"a\": [\"ā\", \"á\", \"ǎ\", \"à\"],  #, \"a\"],\n",
    "        \"A\": [\"Ā\", \"Á\", \"Ǎ\", \"À\"],  #, \"A\"],\n",
    "        \"e\": [\"ē\", \"é\", \"ě\", \"è\"],  #, \"e\"],\n",
    "        \"E\": [\"Ē\", \"É\", \"Ě\", \"È\"],  #, \"E\"],\n",
    "        \"i\": [\"ī\", \"í\", \"ǐ\", \"ì\"],  #, \"i\"],\n",
    "        \"I\": [\"Ī\", \"Í\", \"Ǐ\", \"Ì\"],  #, \"I\"],\n",
    "        \"o\": [\"ō\", \"ó\", \"ǒ\", \"ò\"],  #, \"o\"],\n",
    "        \"O\": [\"Ō\", \"Ó\", \"Ǒ\", \"Ò\"],  #, \"o\"],\n",
    "        \"u\": [\"ū\", \"ú\", \"ǔ\", \"ù\"],  #, \"u\"],\n",
    "        \"U\": [\"Ū\", \"Ú\", \"Ǔ\", \"Ù\"],  #, \"u\"],\n",
    "        \"v\": [\"ǖ\", \"ǘ\", \"ǚ\", \"ǜ\"],  #, \"ü\"],\n",
    "        \"V\": [\"Ǖ\", \"Ǘ\", \"Ǚ\", \"Ǜ\"],  #, \"Ü\"],\n",
    "    }\n",
    "    def vowelToTone(word):\n",
    "        for noAccent, accents in accentMap.items():\n",
    "            for i, accent in enumerate(accents):\n",
    "                if accent in word:\n",
    "                    return f\"{word.replace(accent, noAccent)}{i+1}\"\n",
    "        return f\"{word}5\"\n",
    "        \n",
    "    return \" \".join(vowelToTone(x) for x in pinyin.split(\" \"))\n",
    "\n",
    "df_hsk = df_hsk.assign(pinyin=df_hsk[\"pinyin\"].map(vowelsToTone))\n",
    "df_hsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd022fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q1/w0s_n4x93y30t1tf6m9x42rw0000gn/T/ipykernel_72943/3080385304.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  df_cj = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/mike-fabian/ibus-table-chinese/blob/main/tables/\n",
    "df_cj = pd.read_csv(\n",
    "#     \"data/cangjie5.txt\",\n",
    "    \"data/cangjie-big.txt\",\n",
    "    comment=\"#\",\n",
    "    sep=\"\\t\",\n",
    "    quoting=3,  # csv.QUOTE_NONE\n",
    "#     skiprows=148,\n",
    "    skiprows=160,\n",
    "    skipfooter=2,\n",
    "    keep_default_na=False,\n",
    "    names=[\"cangjie\", \"hanzi\", \"noidea\"],\n",
    ")[[\"hanzi\", \"cangjie\"]]\n",
    "\n",
    "df_cj = (\n",
    "    df_cj\n",
    "    .assign(\n",
    "        hanzi=df_cj[\"hanzi\"].astype(\"string\"),\n",
    "        cangjie=df_cj[\"cangjie\"].astype(\"string\")\n",
    "    )\n",
    "    .groupby(\"hanzi\")\n",
    "    .agg(\"first\")  # first is fine because the only duplicates are weird symbols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df226c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wb = pd.read_csv(\n",
    "    \"data/wubi-haifeng86.UTF-8\",\n",
    "    comment=\"#\",\n",
    "    sep=\"\\t\",\n",
    "    quoting=3,  # csv.QUOTE_NONE\n",
    "    skiprows=0,\n",
    "    skipfooter=0,\n",
    "    keep_default_na=False,\n",
    "    names=[\"wubi\", \"hanzi\", \"noidea\"],\n",
    ")[[\"hanzi\", \"wubi\"]]\n",
    "\n",
    "# not sure what len(hanzi)>1 means when it has a full stop, but just remove\n",
    "df_wb = df_wb[df_wb[\"hanzi\"].map(len).eq(1)]#.groupby(\"hanzi\").agg({\"wubi\": lambda x: \" \".join(x)})\n",
    "df_wb = (\n",
    "    df_wb\n",
    "    .assign(\n",
    "        hanzi=df_wb[\"hanzi\"].astype(\"string\"),\n",
    "        wubi=df_wb[\"wubi\"].astype(\"string\")\n",
    "    )\n",
    "    .groupby(\"hanzi\")\n",
    "    # there are many ways to type the same zi but choose the shortest one for our purposes\n",
    "    .agg(lambda x: min(sorted(x), key=len))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a75f125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2500\n",
       "5    1300\n",
       "4     601\n",
       "3     299\n",
       "1     150\n",
       "2     150\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hsk[\"level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8529d1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2632"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsk_levels = {1,2,3,4,5,6}\n",
    "words = df_hsk[df_hsk[\"level\"].isin(hsk_levels)][\"simplified\"]\n",
    "zi_set = set(''.join(words))\n",
    "len(zi_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "214a1764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cangjie</th>\n",
       "      <th>wubi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanzi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>一</th>\n",
       "      <td>m</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丁</th>\n",
       "      <td>mn</td>\n",
       "      <td>sgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>七</th>\n",
       "      <td>jv</td>\n",
       "      <td>ag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>万</th>\n",
       "      <td>ms</td>\n",
       "      <td>dnv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丈</th>\n",
       "      <td>jk</td>\n",
       "      <td>dyi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cangjie wubi\n",
       "hanzi             \n",
       "一           m    g\n",
       "丁          mn  sgh\n",
       "七          jv   ag\n",
       "万          ms  dnv\n",
       "丈          jk  dyi"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hier = df_cj[df_cj.index.isin(zi_set)].join(df_wb, how=\"inner\")\n",
    "\n",
    "assert len(df_hier) == len(zi_set)\n",
    "assert sum(df_hier[\"cangjie\"].str.contains(\" \")) == 0\n",
    "assert sum(df_hier[\"wubi\"].str.contains(\" \")) == 0\n",
    "\n",
    "df_hier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e7ccc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41a08f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(words: pd.Series):\n",
    "    g = nx.DiGraph()\n",
    "        \n",
    "    for _, word in words.items():\n",
    "        for i in range(len(word) - 1):\n",
    "            source, target = word[i:i+2]\n",
    "            # TODO handle same adjacency for different ci\n",
    "            g.add_edge(source, target, duality=\"adjacency\", ci=word)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94468b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = construct_graph(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a2fefb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129,\n",
       " [1,\n",
       "  2072,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = list(nx.weakly_connected_components(g))\n",
    "len(cc), [len(x) for x in cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26a817b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s_gd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7199d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = g.subgraph(cc[1])\n",
    "zi2idx = {v: i for i, v in enumerate(cc[1])}\n",
    "I = [zi2idx[source] for source, _ in g2.edges]\n",
    "J = [zi2idx[target] for _, target in g2.edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7e7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = s_gd2.layout(I, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9e2bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40296187, -2.08052172],\n",
       "       [ 0.52238526,  0.3472082 ],\n",
       "       [ 3.58395206, -1.14116816],\n",
       "       ...,\n",
       "       [ 0.2359335 , -1.28459933],\n",
       "       [-1.48376138,  1.22610832],\n",
       "       [ 4.41641147, -0.75649418]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8282060",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_gd2.draw_svg(X, I, J, \"stress.svg\", noderadius=.05, nodeopacity=.5, linkopacity=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdb79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
